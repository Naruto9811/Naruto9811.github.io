---

title: "ProNE： Fast and Scalable Network Representation Learning"
author_profile: true
date: 2019-10-28
tags: [Natural Language Processing, network embedding]
mathjax: "true"
header:
    image: "/imgs/blog12.jpg"
excerpt: "Natural Language Processing, network embedding"
---

## 本文探讨的主题：图嵌入 network embedding

## 本文想要解决的问题：构成快速且可随数据集扩展而扩展的图嵌入模型，解决大规模数据集训练慢的问题

## 表示学习与图嵌入

表示学习的目标就是在保留特定性质的同时把一个网络的结构投影到连续的空间中【embedding】。

如今做图嵌入的方法主要分为以下几种：

* 矩阵因式分解：GraRep，HOPE，NetMF

* 基于Skip-Gram的模型：DeepWalk，LINE，node2vec

  有研究表明Skip-Gram是一种隐式的矩阵因式分解，因此产生了NetMF模型

* 图神经网络GNN方法中ConvGNN的spectral-based 方法

  基于谱方法的图嵌入与谱降维技术有关，Isomap，拉普拉斯特征值映射方法，另一个特别重要的工作是想把图谱转换成监督或者半监督图学习，GCN就是这方面的工作

由前两种方法pre-train出的图嵌入经常送给下游的任务来进一步具体化，例如GNN作为下游任务的模型对嵌入进行再训练。

## ProNE 大体思想

ProNE模型就是这种思想的体现，把**稀疏矩阵因式分解**的结果放进ConvGNN中spectral-based的谱传播方法中进行进一步训练。

**系数矩阵因式分解**，学习到的图嵌入表示往往学习到的是局部结构信息。因为本身就是做的局部特征值近似。

**谱传播**，学习到的图嵌入模型往往学习到的是全局网络性质。因为谱传播方法本身就是对整张图进行的谱空间变换，获得的会是全局聚类信息和局部平滑。

ProNE 有几个非常惹人入目的优点：

* 训练非常地快，由于计算矩阵的 **稀疏** 性和稀疏随机矩阵SVD技术的使用，时间复杂度得到了很大的优化,时间复杂度只有$O(k|E|+|V|d^2)$
* 效果非常地好，在比传统方法快很多的情况下，模型准确率超过了之前的所有方法
* 谱传播方法具有普适性，用在 ProNE 模型中的谱传播方法对于嵌入的增强在 DeepWalk，LINE，node2vec，GraGrep，HOPE中使用谱传播技术均可以非常有效地提升模型嵌入效果
* 具有可扩展性，ProNE的训练时间和图网络的规模成线性增长关系，训练时间和网络的稠密程度也成线性增长关系。所以ProNE模型有适用于大规模数据集的可能性，并且可以大概预测出训练时间
* 由于稀疏矩阵的乘积可以通过并行运算进行处理，而稀疏矩阵的处理占了ProNE模型计算的很大一部分，所以ProNE模型的**多线程并行**优化效果好。

 ## ProNE 具体原理

分两步对模型具体内容进行讲解：

* **稀疏矩阵因式分解作为快速图嵌入技术【速度快】**

  这个高效的稀疏矩阵因式分解方法技术思想来源于Harris 提出的distributional hypothesis。即认为一个单词的含义由其周围词决定，若是两个单词的周围词想接近，那么就可以认为一定程度上两个单词的含义相近。

* **谱传播作为图嵌入增强技术【效果好】**



